title: Ahyane
tags: ahyane


Walkers:
how best to implement an "onstart" and "onfinish" events for walking the tree?  kind of necessary.


So, having to manage content in a folder structure, like I suggested below.  That sucks.  Fuck that.

New plan: the metadata on a piece of content is what determines where it goes.  Organize the content folder however you like, so long as the metadata is good.

If it has a date, it gets put in the dated archives.
If it has tags, it gets put in the category archives.
If it has an author, it gets put in the author archives

Type values:
static - a static (non-dated) page, akin to Wordpress's "pages". default if no date on the thing
draft - not published
blog - a blog post in the date archives (default if there's a date on the thing.)

url-titles:
If the thing has a "stub" metadata, use that.  Otherwise, use the sanitized title.

Permalinks: 
If the thing has a date, then the canonical link is: /yyyy/dd/url-title/
If it doesn't have a date, or if the "type" is "static", then the permalink is /url-title/






-=-=-=-=- -=-=-=-=- -=-=-=-=- -=-=-=-=- -=-=-=-=- -=-=-=-=- 


Foohack CMS

the problem is, it doesn't make sense to organize content in quite the same way as the url schema.  Or does it, at least for the "normal" year/month folders?

content/2008/07/blah-blah-blah.txt maybe?

and then also, a content/drafts/ folder for stuff that isn't published yet.  The "publish" mechanism is to move the content file into the year/month folders.

So, that means I can take a few shortcuts.  All nodes with a path matching /[0-9]{4}/[0-9]{2}/ can be considered blog posts.  Anything else is a static page.


-=-=-=-=- -=-=-=-=- -=-=-=-=- -=-=-=-=- -=-=-=-=- -=-=-=-=- -=-=-=-=-

1. parse the /content folder, and build a tree structure of folders and files.
2. walk over the tree various times, doing various things to it.
3. end up with a URL tree structure.
4. serialize this URL tree structure so that it can be used as a starting point later for other things.

Each piece in this tree has three things:

* pathPiece => folder or filename, eventually part of the path in a uri
* content => the content in this node.  this is basically a data blob of text content and meta data.  After the first parse, for example, all the file nodes have the parse of their content here.  List pages eventually have the excerpts of their children in an array or something.  etc.
* transforms => an array of transform functions that have to be run on this node when it is written.
* children => an array of nodes.  from the initial parse, 




For each data node in this url tree:

1. parse the file it points to
2. pass the data through the required transforms.
3. write the data to the URL folder.




















Things that need to be built:
/2008/03/01/ (day urls)
/2008/03/01/page/2/ (paged)
/2008/03/ (month urls)
/2008/03/page/2/ (paged)
/2008/ (year urls)
/2008/page/2/ (paged)
/about/ (static pages)

/about/rss/ (rss versions of everything that's been built)
/2008/03/rss/
/2008/03/page/2/rss/

/category/the-business/
/category/the-business/page/2/


searching... hm......
Could just use google.  But it would be cool to have a special task that greps the content folder.



/content/YYYY/MM/post-name.txt
/content/page-name.txt
text files with content.  filename == nicetitle.


/config/...
data about server to send it to, file to put it in, disqus id, etc.
number of posts to show on a page.


/tpl/
The template files that take a data object and spit out the content.


/bin/
builder script (and cron)
--> if the cron fails, send an XMPP message.
disqus api fetch stuff
paragraphizing/nicequotes/etc.


/build/
the rendered files.
/page-name for all pages.
/YYYY/MM/the-titel for all posts.
/category/blah-dee-bloo
/YYYY/MM/


conf file:
RewriteCond !-f %{REQUEST_FILENAME}
RewriteCond -f ./build/%{REQUEST_URI}.html
RewriteRule (.*) /build/$1.html [L]

ErrorHandler 404 /404.html


File format:

header: value
header: value

content content content.

-=- -=- -=- -=- -=- -=- -=- -=- -=- -=- -=- -=- -=- -=- -=- -=- -=- -=- -=- 
TODO:

