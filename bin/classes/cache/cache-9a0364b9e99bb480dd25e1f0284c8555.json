throw 1; '<foo'hack</script>{"name":"content","content":null,"children":{"2008":{"name":"2008","content":null,"children":{"01":{"name":"01","content":null,"children":{"content-in-2k8.txt":{"name":"content-in-2k8.txt","content":"date: 2008-01-02\ntitle: Content in 2008\n\nthis is some content.  It occurs in 2008, but also in January and on the 2nd. It was a nice year."}}}}},"ideas":{"name":"ideas","content":"Foohack CMS\n\nthe problem is, it doesn't make sense to organize content in quite the same way as the url schema.  Or does it, at least for the \"normal\" year\/month folders?\n\ncontent\/2008\/07\/blah-blah-blah.txt maybe?\n\nand then also, a content\/drafts\/ folder for stuff that isn't published yet.  The \"publish\" mechanism is to move the content file into the year\/month folders.\n\nSo, that means I can take a few shortcuts.  All nodes with a path matching \/[0-9]{4}\/[0-9]{2}\/ can be considered blog posts.  Anything else is a static page.\n\n\n\n\n\n\n\n\n\n\n\n\n\n-=-=-=-=- -=-=-=-=- -=-=-=-=- -=-=-=-=- -=-=-=-=- -=-=-=-=- -=-=-=-=-\n\n1. parse the \/content folder, and build a tree structure of folders and files.\n2. walk over the tree various times, doing various things to it.\n3. end up with a URL tree structure.\n4. serialize this URL tree structure so that it can be used as a starting point later for other things.\n\nEach piece in this tree has three things:\n\n* pathPiece => folder or filename, eventually part of the path in a uri\n* content => the content in this node.  this is basically a data blob of text content and meta data.  After the first parse, for example, all the file nodes have the parse of their content here.  List pages eventually have the excerpts of their children in an array or something.  etc.\n* transforms => an array of transform functions that have to be run on this node when it is written.\n* children => an array of nodes.  from the initial parse, \n\n\n\n\nFor each data node in this url tree:\n\n1. parse the file it points to\n2. pass the data through the required transforms.\n3. write the data to the URL folder.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings that need to be built:\n\/2008\/03\/01\/ (day urls)\n\/2008\/03\/01\/page\/2\/ (paged)\n\/2008\/03\/ (month urls)\n\/2008\/03\/page\/2\/ (paged)\n\/2008\/ (year urls)\n\/2008\/page\/2\/ (paged)\n\/about\/ (static pages)\n\n\/about\/rss\/ (rss versions of everything that's been built)\n\/2008\/03\/rss\/\n\/2008\/03\/page\/2\/rss\/\n\n\/category\/the-business\/\n\/category\/the-business\/page\/2\/\n\n\nsearching... hm......\nCould just use google.  But it would be cool to have a special task that greps the content folder.\n\n\n\n\/content\/YYYY\/MM\/post-name.txt\n\/content\/page-name.txt\ntext files with content.  filename == nicetitle.\n\n\n\/config\/...\ndata about server to send it to, file to put it in, disqus id, etc.\nnumber of posts to show on a page.\n\n\n\/tpl\/\nThe template files that take a data object and spit out the content.\n\n\n\/bin\/\nbuilder script (and cron)\n--> if the cron fails, send an XMPP message.\ndisqus api fetch stuff\nparagraphizing\/nicequotes\/etc.\n\n\n\/build\/\nthe rendered files.\n\/page-name for all pages.\n\/YYYY\/MM\/the-titel for all posts.\n\/category\/blah-dee-bloo\n\/YYYY\/MM\/\n\n\nconf file:\nRewriteCond !-f %{REQUEST_FILENAME}\nRewriteCond -f .\/build\/%{REQUEST_URI}.html\nRewriteRule (.*) \/build\/$1.html [L]\n\nErrorHandler 404 \/404.html\n\n\nFile format:\n\nheader: value\nheader: value\n\ncontent content content.\n\n-=- -=- -=- -=- -=- -=- -=- -=- -=- -=- -=- -=- -=- -=- -=- -=- -=- -=- -=- \nTODO:\n\n"},"static-page.txt":{"name":"static-page.txt","content":"title: Some Content\n\n1492 was a very good year.\n\nhere's another paragraph."},"test":{"name":"test","content":null,"children":{"index.txt":{"name":"index.txt","content":"title: test\ncategory: testing\ndate: 2007-01-01\n\nthe main test."},"number2.txt":{"name":"number2.txt","content":"\n\n\nthe child test, sans headers."}}}}}